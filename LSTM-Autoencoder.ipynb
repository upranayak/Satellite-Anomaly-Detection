{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "from numpy import ma\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib import ticker, cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.datasets import imdb\n",
    "#from keras import preprocessing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models, regularizers, layers, optimizers, losses, metrics\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling1D\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import seaborn as sns\n",
    "from matplotlib.pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted')\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "print('Tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c5623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRaw = pd.read_csv('SampleInput.txt', sep='\\s+', header=None)\n",
    "RawTS = dataRaw.copy()\n",
    "print(RawTS.shape)\n",
    "RawTS.columns = ['year', 'day', 'hour', 'minute', 'second', 'millisecond', 'val1', 'val2', 'val3', 'val4', 'val5', 'val6', 'val7', 'val8', 'val9', 'val10', 'val11', 'val12', 'val13', 'val14', 'val15', 'val16', 'val17', 'val18', 'val19', 'val20', 'val21', 'val22']\n",
    "RawTS.reset_index(inplace=True)\n",
    "RawTS.rename(columns={'index': 'Serial Number'}, inplace=True)\n",
    "# RawTS.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_to_month_date(day):\n",
    "    months = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "    \n",
    "    month_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    \n",
    "    # Check for leap year\n",
    "    year = 2023\n",
    "    if (year % 4 == 0 and year % 100 != 0) or year % 400 == 0:\n",
    "        month_days[1] = 29\n",
    "    \n",
    "    # Find the corresponding month and date\n",
    "    month = 0\n",
    "    while day > month_days[month]:\n",
    "        day -= month_days[month]\n",
    "        month += 1\n",
    "    \n",
    "    return months[month], day\n",
    "\n",
    "# # Example usage\n",
    "day = 253\n",
    "month, date = day_to_month_date(day)\n",
    "print(f\"{day} is {month} {date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates= []\n",
    "months= []\n",
    "for days in RawTS['day']:\n",
    "    month, date = day_to_month_date(days)\n",
    "    dates.append(date)\n",
    "    months.append(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a5119",
   "metadata": {},
   "outputs": [],
   "source": [
    "RawTS.insert(loc=1, column='Month', value=months)\n",
    "RawTS.insert(loc=1, column='Date', value=dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d78ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = RawTS['year'].astype(str) +\"-\"+ RawTS[\"Month\"].astype(str)+\"-\"+ RawTS[\"Date\"].astype(str) +\" \"+RawTS['hour'].astype(str) +\":\"+ RawTS[\"minute\"].astype(str) +\":\"+RawTS['second'].astype(str) +\".\"+ RawTS[\"millisecond\"].astype(str)\n",
    "RawTS.insert(loc=1, column='TimeStamp', value=new_col)\n",
    "new_col[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae2aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RawTS.set_index(pd.to_datetime(RawTS['TimeStamp']), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b6c14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2af845",
   "metadata": {},
   "outputs": [],
   "source": [
    "RawTS['val14'] = RawTS['val14'].replace({'SYNC': 1, 'NO_SYNC': 0})\n",
    "RawTS['val15'] = RawTS['val15'].replace({'ON': 1, 'OFF': 0})\n",
    "RawTS['val16'] = RawTS['val16'].replace({'ON': 1, 'OFF': 0})\n",
    "RawTS['val17'] = RawTS['val17'].replace({'ON': 1, 'OFF': 0})\n",
    "RawTS['val18'] = RawTS['val18'].replace({'SYNC': 1, 'NO_SYNC': 0})\n",
    "RawTS['val19'] = RawTS['val19'].replace({'USBL': 1, 'NOT_USBL': 0})\n",
    "RawTS['val22'] = RawTS['val22'].replace({'ON': 1, 'OFF': 0})\n",
    "RawTS['val21'] = RawTS['val21'].replace({'LOW': 0, 'HIGH': 1})\n",
    "RawTS['val20'] = RawTS['val22'].replace({'ENA': 1, 'DIS': 0})\n",
    "# RawTS = RawTS.drop('val21', axis=1)\n",
    "# RawTS = RawTS.drop('val19', axis=1)\n",
    "RawTS = RawTS.drop('val1', axis=1)\n",
    "RawTS = RawTS.drop('year', axis=1)\n",
    "RawTS = RawTS.drop('day', axis=1)\n",
    "RawTS = RawTS.drop('Month', axis=1)\n",
    "RawTS = RawTS.drop('Date', axis=1)\n",
    "RawTS = RawTS.drop('hour', axis=1)\n",
    "RawTS = RawTS.drop('minute', axis=1)\n",
    "RawTS = RawTS.drop('second', axis=1)\n",
    "RawTS = RawTS.drop('millisecond', axis=1)\n",
    "\n",
    "#RawTS['val1'] = RawTS['val1'].replace(RawTS['val1']/4)\n",
    "RawTS.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ee7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RawTS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d6823",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,23):\n",
    "    RawTS[f'val{i}']=RawTS[f'val{i}'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b5ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('SampleInput.txt', sep='\\s+', header=None)\n",
    "print(labels.shape)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6767e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.value_counts(), labels.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7809d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RawTS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91abe358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(2,23):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=RawTS['TimeStamp'], y=RawTS[f'val{i}'],name=f'VAL{i}'))\n",
    "    fig.update_layout(showlegend=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dbc6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(RawTS) * 0.7)\n",
    "test_size = len(RawTS) - train_size\n",
    "train, test = RawTS.iloc[0:train_size], RawTS.iloc[train_size:len(RawTS)]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd72b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)        \n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "anomaly={}\n",
    "for i in range(2,23):\n",
    "    time_steps = 30\n",
    "\n",
    "    X_train, y_train = create_dataset(train[[f'val{i}']], train[f'val{i}'], time_steps)\n",
    "    X_test, y_test = create_dataset(test[[f'val{i}']], test[f'val{i}'], time_steps)\n",
    "    np.random.seed(21)\n",
    "    tf.random.set_seed(21)\n",
    "    timesteps = X_train.shape[1]\n",
    "    num_features = X_train.shape[2]\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n",
    "\n",
    "    model = Sequential([\n",
    "        LSTM(128, input_shape=(timesteps, num_features)),\n",
    "        Dropout(0.2),\n",
    "        RepeatVector(timesteps),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(num_features))                 \n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    model.summary()\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min')\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=5,\n",
    "        batch_size=32,\n",
    "        validation_split=0.1,\n",
    "        callbacks = [es],\n",
    "        shuffle=False\n",
    "    )\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend();\n",
    "    X_train_pred = model.predict(X_train)\n",
    "    train_mae_loss = pd.DataFrame(np.mean(np.abs(X_train_pred - X_train), axis=1), columns=['Error'])\n",
    "    # Mean Absolute Error loss\n",
    "    X_train_pred = model.predict(X_train)\n",
    "    train_mae_loss = np.mean(np.abs(X_train_pred - X_train), axis=1)\n",
    "\n",
    "    plt.hist(train_mae_loss, bins=50)\n",
    "    plt.xlabel('Train MAE loss')\n",
    "    plt.ylabel('Number of Samples');\n",
    "\n",
    "    # Set reconstruction error threshold\n",
    "    threshold = np.max(train_mae_loss)\n",
    "\n",
    "    print('Reconstruction error threshold:',threshold)\n",
    "    model.evaluate(X_test, y_test)\n",
    "    sns.distplot(train_mae_loss, bins=50, kde=True);\n",
    "    X_test_pred = model.predict(X_test)\n",
    "\n",
    "    test_mae_loss = np.mean(np.abs(X_test_pred - X_test), axis=1)\n",
    "    sns.distplot(test_mae_loss, bins=50, kde=True);\n",
    "#     threshold = 0.23\n",
    "    anomaly_df = pd.DataFrame(test[30:])\n",
    "    anomaly_df['loss'] = test_mae_loss\n",
    "    anomaly_df['threshold'] = threshold\n",
    "    anomaly_df['anomaly'] = anomaly_df['loss'] > anomaly_df['threshold']\n",
    "    anomalies = anomaly_df.loc[anomaly_df['anomaly'] == True]\n",
    "    anomaly[f'anomaly_var{i}'] = anomalies\n",
    "#     anomaly_df.head()\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=anomaly_df['TimeStamp'], y=anomaly_df['loss'], name='Test loss'))\n",
    "    fig.add_trace(go.Scatter(x=anomaly_df['TimeStamp'], y=anomaly_df['threshold'], name='Threshold'))\n",
    "    fig.update_layout(showlegend=True, title='Test loss vs. Threshold')\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
